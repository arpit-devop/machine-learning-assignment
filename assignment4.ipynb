{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ffSneolq64x",
        "outputId": "1a2bf2fb-49b7-4bb6-d175-27e73fdac999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Scraping complete! Saved to books.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "books = []\n",
        "\n",
        "# Loop through all 50 pages\n",
        "for page in range(1, 51):\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    for book in soup.find_all(\"article\", class_=\"product_pod\"):\n",
        "        title = book.h3.a[\"title\"]\n",
        "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
        "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "        star_rating = book.p[\"class\"][1]  # class=\"star-rating Three\" → [\"star-rating\",\"Three\"]\n",
        "\n",
        "        books.append([title, price, availability, star_rating])\n",
        "\n",
        "# Store in DataFrame\n",
        "df_books = pd.DataFrame(books, columns=[\"Title\", \"Price\", \"Availability\", \"Star Rating\"])\n",
        "df_books.to_csv(\"books.csv\", index=False)\n",
        "print(\"✅ Scraping complete! Saved to books.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "\n",
        "# Configure Chrome options for headless mode\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "driver.get(url)\n",
        "time.sleep(3)  # wait for page to load\n",
        "\n",
        "movies = []\n",
        "\n",
        "rows = driver.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list-summary-item\")\n",
        "for rank, row in enumerate(rows, start=1):\n",
        "    title = row.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "    year = row.find_element(By.CSS_SELECTOR, \".cli-title-metadata-item\").text\n",
        "    rating = row.find_element(By.CSS_SELECTOR, \".ipc-rating-star\").text.split()[0]\n",
        "    movies.append([rank, title, year, rating])\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "df_movies = pd.DataFrame(movies, columns=[\"Rank\", \"Movie Title\", \"Year\", \"IMDB Rating\"])\n",
        "df_movies.to_csv(\"imdb_top250.csv\", index=False)\n",
        "print(\"✅ IMDB Top 250 saved to imdb_top250.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LV5ktasr7iC",
        "outputId": "b515f3d9-c533-4e61-8e3b-02f70af94970"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ IMDB Top 250 saved to imdb_top250.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "cities = []\n",
        "for row in soup.select(\"table tbody tr\"):\n",
        "    try:\n",
        "        city = row.find(\"a\").text\n",
        "        temp = row.find(\"td\", class_=\"rbi\").text\n",
        "        condition = row.find_all(\"td\")[2].text\n",
        "        cities.append([city, temp, condition])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "df_weather = pd.DataFrame(cities, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
        "df_weather.to_csv(\"weather.csv\", index=False)\n",
        "print(\"✅ Weather data saved to weather.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBT9Ndi5sOHN",
        "outputId": "db6abe74-cd4f-4039-98c4-b47c97520bdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Weather data saved to weather.csv\n"
          ]
        }
      ]
    }
  ]
}