{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpENi6Xql6yiFHwLc4aWiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpit-devop/machine-learning-assignment/blob/main/ml3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F9p0FpEjwDr",
        "outputId": "891d7c23-5d00-466d-9ca4-a412130bd96e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best R2 (CV): 0.9243869413350316\n",
            "Train R2: 0.9192672043633922 Test R2: 0.9147458156636434\n"
          ]
        }
      ],
      "source": [
        "# Q1: USA House Price Prediction - 5-fold Cross Validation with Least Squares\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "\n",
        "data = pd.read_csv('/content/USA_Housing.csv')\n",
        "\n",
        "# Separate input features and output variable\n",
        "X = data.drop('Price', axis=1).values\n",
        "y = data['Price'].values\n",
        "\n",
        "# Scale input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores = []\n",
        "betas = []\n",
        "\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    # Compute least squares beta\n",
        "    X_train_ = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
        "    beta = np.linalg.inv(X_train_.T @ X_train_) @ X_train_.T @ y_train\n",
        "    X_test_ = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
        "    y_pred = X_test_ @ beta\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "    betas.append(beta)\n",
        "\n",
        "best_idx = np.argmax(r2_scores)\n",
        "best_beta = betas[best_idx]\n",
        "\n",
        "# Train/Test Split (70/30) using best beta\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "X_tr_ = np.hstack([np.ones((X_tr.shape[0], 1)), X_tr])\n",
        "X_te_ = np.hstack([np.ones((X_te.shape[0], 1)), X_te])\n",
        "y_tr_pred = X_tr_ @ best_beta\n",
        "y_te_pred = X_te_ @ best_beta\n",
        "r2_train = r2_score(y_tr, y_tr_pred)\n",
        "r2_test = r2_score(y_te, y_te_pred)\n",
        "\n",
        "print(\"Best R2 (CV):\", r2_scores[best_idx])\n",
        "print(\"Train R2:\", r2_train, \"Test R2:\", r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2: Train/Val/Test split and Gradient Descent for Multiple Linear Regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train/Val/Test split: 56% train, 14% validation, 30% test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "val_size = 0.14 / (0.56 + 0.14)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size, random_state=42)\n",
        "\n",
        "def gradient_descent(X, y, lr=0.01, n_iters=1000):\n",
        "    n_samples, n_features = X.shape\n",
        "    beta = np.zeros(n_features)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ beta\n",
        "        grad = -2/n_samples * (X.T @ (y - y_pred))\n",
        "        beta = beta - lr * grad\n",
        "    return beta\n",
        "\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "r2_val_scores, r2_test_scores, betas = [], [], []\n",
        "\n",
        "X_train_ = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
        "X_val_ = np.hstack([np.ones((X_val.shape[0], 1)), X_val])\n",
        "X_test_ = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
        "\n",
        "for lr in learning_rates:\n",
        "    beta = gradient_descent(X_train_, y_train, lr, 1000)\n",
        "    betas.append(beta)\n",
        "    y_val_pred = X_val_ @ beta\n",
        "    y_test_pred = X_test_ @ beta\n",
        "    r2_val = r2_score(y_val, y_val_pred)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "    r2_val_scores.append(r2_val)\n",
        "    r2_test_scores.append(r2_test)\n",
        "\n",
        "best_idx = np.argmax(r2_val_scores)\n",
        "best_beta = betas[best_idx]\n",
        "\n",
        "print(f\"Best learning rate: {learning_rates[best_idx]}\")\n",
        "print(f\"Validation R2: {r2_val_scores[best_idx]}, Test R2: {r2_test_scores[best_idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8dX3u8fj9AL",
        "outputId": "9fd5cd26-e172-4863-d328-1dfab75bcdd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best learning rate: 0.01\n",
            "Validation R2: 0.909799626728122, Test R2: 0.9147569598865972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3: Car Price Prediction - Preprocessing and Multiple Linear Regression\n",
        "\n",
        "# Column names for the dataset\n",
        "columns = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
        "           \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
        "           \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\",\n",
        "           \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "car_df = pd.read_csv(url, names=columns, na_values=\"?\")\n",
        "\n",
        "# Imputation\n",
        "for col in car_df.columns:\n",
        "    if car_df[col].dtype == 'object':\n",
        "        car_df[col] = car_df[col].fillna(car_df[col].mode()[0])\n",
        "    else:\n",
        "        car_df[col] = car_df[col].fillna(car_df[col].median())\n",
        "\n",
        "car_df.dropna(subset=['price'], inplace=True)\n",
        "\n",
        "# Convert non-numeric values\n",
        "num_map = {'four':4,'two':2,'three':3,'five':5,'six':6,'eight':8,'twelve':12}\n",
        "car_df['num_doors'] = car_df['num_doors'].replace(num_map)\n",
        "car_df['num_cylinders'] = car_df['num_cylinders'].replace(num_map)\n",
        "\n",
        "\n",
        "car_df = pd.get_dummies(car_df, columns=[\"body_style\", \"drive_wheels\"])\n",
        "\n",
        "# Convert boolean columns to int\n",
        "bool_cols = car_df.select_dtypes(include='bool').columns\n",
        "for col in bool_cols:\n",
        "    car_df[col] = car_df[col].astype(int)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for col in [\"make\", \"aspiration\", \"engine_location\",\"fuel_type\"]:\n",
        "    car_df[col] = LabelEncoder().fit_transform(car_df[col])\n",
        "car_df['fuel_system'] = car_df['fuel_system'].apply(lambda x: 1 if \"pfi\" in str(x) else 0)\n",
        "car_df['engine_type'] = car_df['engine_type'].apply(lambda x: 1 if \"ohc\" in str(x) else 0)\n",
        "\n",
        "# Explicitly convert all columns to numeric before creating NumPy array X\n",
        "print(\"\\nDataFrame dtypes before converting to NumPy array:\")\n",
        "print(car_df.dtypes)\n",
        "\n",
        "# Convert DataFrame to float type before creating NumPy array\n",
        "car_df = car_df.astype(float)\n",
        "\n",
        "# Check for NaNs in DataFrame after converting to float\n",
        "print(\"\\nMissing values in DataFrame after converting to float:\")\n",
        "print(car_df.isnull().sum())\n",
        "\n",
        "# Separate features and target, scale inputs\n",
        "X = car_df.drop('price', axis=1).values\n",
        "y = car_df['price'].values\n",
        "\n",
        "\n",
        "\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Train/test split (70/30)\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_tr, y_tr)\n",
        "y_pred_te = reg.predict(X_te)\n",
        "r2_full = r2_score(y_te, y_pred_te)\n",
        "\n",
        "# PCA + Regression\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=min(X_tr.shape[1], 10))\n",
        "X_tr_pca = pca.fit_transform(X_tr)\n",
        "X_te_pca = pca.transform(X_te)\n",
        "reg_pca = LinearRegression()\n",
        "reg_pca.fit(X_tr_pca, y_tr)\n",
        "y_pred_te_pca = reg_pca.predict(X_te_pca)\n",
        "r2_pca = r2_score(y_te, y_pred_te_pca)\n",
        "\n",
        "print(\"Normal Linear Regression Test R2:\", r2_full)\n",
        "print(\"PCA-based Regression Test R2:\", r2_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGENYk5VlAFx",
        "outputId": "ffdb934e-ea55-4436-ce99-473a9a62f2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame dtypes before converting to NumPy array:\n",
            "symboling                   int64\n",
            "normalized_losses         float64\n",
            "make                        int64\n",
            "fuel_type                   int64\n",
            "aspiration                  int64\n",
            "num_doors                   int64\n",
            "engine_location             int64\n",
            "wheel_base                float64\n",
            "length                    float64\n",
            "width                     float64\n",
            "height                    float64\n",
            "curb_weight                 int64\n",
            "engine_type                 int64\n",
            "num_cylinders               int64\n",
            "engine_size                 int64\n",
            "fuel_system                 int64\n",
            "bore                      float64\n",
            "stroke                    float64\n",
            "compression_ratio         float64\n",
            "horsepower                float64\n",
            "peak_rpm                  float64\n",
            "city_mpg                    int64\n",
            "highway_mpg                 int64\n",
            "price                     float64\n",
            "body_style_convertible      int64\n",
            "body_style_hardtop          int64\n",
            "body_style_hatchback        int64\n",
            "body_style_sedan            int64\n",
            "body_style_wagon            int64\n",
            "drive_wheels_4wd            int64\n",
            "drive_wheels_fwd            int64\n",
            "drive_wheels_rwd            int64\n",
            "dtype: object\n",
            "\n",
            "Missing values in DataFrame after converting to float:\n",
            "symboling                 0\n",
            "normalized_losses         0\n",
            "make                      0\n",
            "fuel_type                 0\n",
            "aspiration                0\n",
            "num_doors                 0\n",
            "engine_location           0\n",
            "wheel_base                0\n",
            "length                    0\n",
            "width                     0\n",
            "height                    0\n",
            "curb_weight               0\n",
            "engine_type               0\n",
            "num_cylinders             0\n",
            "engine_size               0\n",
            "fuel_system               0\n",
            "bore                      0\n",
            "stroke                    0\n",
            "compression_ratio         0\n",
            "horsepower                0\n",
            "peak_rpm                  0\n",
            "city_mpg                  0\n",
            "highway_mpg               0\n",
            "price                     0\n",
            "body_style_convertible    0\n",
            "body_style_hardtop        0\n",
            "body_style_hatchback      0\n",
            "body_style_sedan          0\n",
            "body_style_wagon          0\n",
            "drive_wheels_4wd          0\n",
            "drive_wheels_fwd          0\n",
            "drive_wheels_rwd          0\n",
            "dtype: int64\n",
            "Normal Linear Regression Test R2: 0.7962231220908706\n",
            "PCA-based Regression Test R2: 0.7848974624944537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1941833843.py:24: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  car_df['num_doors'] = car_df['num_doors'].replace(num_map)\n",
            "/tmp/ipython-input-1941833843.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  car_df['num_cylinders'] = car_df['num_cylinders'].replace(num_map)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Os8rX4Zblxar"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}